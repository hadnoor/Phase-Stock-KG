{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# ------- H1: DATASET UTILS -------------\n",
    "\n",
    "# ------- H2: Preprocess Data -------------\n",
    "def window_scale_divison(df, W, T, company_to_id, ticker):\n",
    "    \"\"\"\n",
    "        Returns the window of input and target values scaled by dividing with the\n",
    "        last value of the previous window.\n",
    "\n",
    "        Problems: With large W and T\n",
    "    \"\"\"\n",
    "    SMOOTH = 0.00001\n",
    "    list_df = [(\n",
    "                    (df['Open'][i+1:i+W+1] / df['Open'][i:i+1].values+SMOOTH).values, \n",
    "                    (df['High'][i+1:i+W+1] / df['High'][i:i+1].values+SMOOTH).values,           \n",
    "                    (df['Low'][i+1:i+W+1] / df['Low'][i:i+1].values+SMOOTH).values, \n",
    "                    (df['Close'][i+1:i+W+1] / df['Close'][i:i+1].values+SMOOTH).values,           \n",
    "                    (df['Volume'][i+1:i+W+1] / (df['Volume'][i:i+1].values+SMOOTH)).values, \n",
    "                    company_to_id[ticker],  \n",
    "                    df[i+1:i+W+1]['Date'], \n",
    "                    [\n",
    "                        (df['Close'][i+W+T:i+W+T+1] / df['Close'][i+W:i+W+1].values).values\n",
    "                        for T in [1, 5, 20]\n",
    "                    ], \n",
    "                    df['Close'][i+W:i+W+1],\n",
    "                    df.iloc[i+W:i+W+1, 7:].values,\n",
    "                    [\n",
    "                        (df['Low'][i+W+T:i+W+T+1]).values\n",
    "                        for T in [0, 1, 5, 20]\n",
    "                    ], \n",
    "                    [\n",
    "                        (df['High'][i+W+T:i+W+T+1]).values\n",
    "                        for T in [0, 1, 5, 20]\n",
    "                    ]\n",
    "                ) \n",
    "                for i in range(df.shape[0]-W-T)\n",
    "            ]\n",
    "    \n",
    "    return list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AMZN-Amazon.Com Inc..csv\n"
     ]
    }
   ],
   "source": [
    "directory = \"data/\" + \"nasdaq_2\" + \"/\"\n",
    "W=20\n",
    "T=5\n",
    "company_to_id = {}\n",
    "company_id    = 0\n",
    "\n",
    "dataset = []\n",
    "df_map = {}\n",
    "skipped_ticker = []\n",
    "total = 0\n",
    "for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    if os.path.isfile(f):\n",
    "        print(filename)\n",
    "        ticker, name = filename.split(\"-\")\n",
    "        df = pd.read_csv(f)\n",
    "        df = df.fillna(method='ffill')\n",
    "\n",
    "        if df.shape[0] <= 2800:    # 13 years\n",
    "            print(\"Skipping file: Less Training-Testing samples [{0} samples]\".format(df.shape[0]))\n",
    "            skipped_ticker.append(ticker)\n",
    "            continue\n",
    "        total += 1\n",
    "\n",
    "        if ticker not in company_to_id:\n",
    "            company_to_id[ticker] = company_id\n",
    "            company_id += 1\n",
    "        \n",
    "        \n",
    "        if df.shape[0] > 2800:\n",
    "            df = df.iloc[-2800:]\n",
    "    \n",
    " \n",
    "        list_df = [(\n",
    "                df.iloc[i+W:i+W+1, 7:].shape\n",
    "            ) \n",
    "            for i in range(df.shape[0]-W-T)\n",
    "        ]\n",
    "\n",
    "        list_df = window_scale_divison(df, W, T, company_to_id, ticker)\n",
    "        df_map[company_to_id[ticker]] = list_df\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list_df[0][0][0])\n",
    "def normalize():\n",
    "    \n",
    "\n",
    "for i in [0,1,2,3]:\n",
    "    list_df[0][0][i] = normalize(list_df[0][0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"data/pickle/\"+\"nasdaqnew\"+\"/full_graph_data_correct-P25-W\"+str(20)+\"-T\"+str(5)+\"_\"+str(\"True\")+\".pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataset_graph(save_path, dataset, company_to_id, graph, hyper_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #parser = argparse.ArgumentParser()\n",
    "    #parser.add_argument('--index', type=str, default=\"AAPL\")\n",
    "    #parser.add_argument('--window', type=int, default=10)\n",
    "    #parser.add_argument('--test_size', type=float, default=0.2)\n",
    "\n",
    "    #create_dataset(\"nasdaq100\", 50, 5)\n",
    "    d, s, c, g, h = create_batch_dataset(\"nasdaq100\", 50, 5)\n",
    "    print(len(d[0]), len(d[0][0]), d[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
